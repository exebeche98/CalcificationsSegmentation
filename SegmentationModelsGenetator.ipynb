{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import segmentation_models as sm # sm.__version__ '1.0.1'\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "import random\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "sm.set_framework('tf.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f94730",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Folders structure:\n",
    "basepath contains train and test folders\n",
    "in my case .../basepath/code/current_code_folder\n",
    "\n",
    "img_path - contains patches 128x128 png files\n",
    "msk_path - contains corresponding masks files\n",
    "\n",
    "Train contains only images with target class the data is very imbalanced,\n",
    "the content of the target classis significantly less than the background\n",
    "and we should focus on the target class.\n",
    "\n",
    "Test sample is used to quick model evaluation during training and also\n",
    "contains only those images on which the target class is present. \n",
    "\n",
    "The validation set contains all images obtained during slicing\n",
    "and is used for an objective final evaluation of the model.\n",
    "'''\n",
    "#basepath = 'C:/Users/UserName/Desktop/basepath/'\n",
    "basepath = os.path.dirname(os.path.dirname((os.getcwd()).replace('\\\\', '/'))) + '/'\n",
    "\n",
    "###train\n",
    "train_img_path = basepath + 'train/patches/img/'\n",
    "train_msk_path = basepath + 'train/patches_msk/img/' \n",
    "###test\n",
    "test_img_path = basepath + 'test/patches/img/'\n",
    "test_msk_path = basepath + 'test/patches_msk/img/'\n",
    "###valid\n",
    "valid_img_path = basepath + 'test/patches/'\n",
    "valid_msk_path = basepath + 'test/patches_msk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ced9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(img_dir, msk_dir):\n",
    "    '''\n",
    "    It is good practice to check\n",
    "    is the images match the masks before training.\n",
    "    '''\n",
    "    img_list = os.listdir(img_dir)\n",
    "    msk_list = os.listdir(msk_dir)\n",
    "    \n",
    "    num_images = len(img_list)\n",
    "    img_num = random.randint(0, num_images-1)\n",
    "\n",
    "    img_for_plot = cv2.imread(img_dir + img_list[img_num], 1)\n",
    "    img_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mask_for_plot =cv2.imread(msk_dir + msk_list[img_num], 0)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img_for_plot)\n",
    "    plt.title('Image')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(mask_for_plot, cmap='gray')\n",
    "    plt.title('Mask')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c6c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "launch this code a few times to make sure that masks corespond to image\n",
    "'''\n",
    "sanity_check(train_img_path, train_msk_path)\n",
    "sanity_check(test_img_path, test_msk_path)\n",
    "sanity_check(valid_img_path, valid_msk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb937e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_images = []\n",
    "train_masks = []\n",
    "test_images = []\n",
    "test_masks = []\n",
    "\n",
    "\n",
    "#3 chanels because segmentation models expect 3 chanel image\n",
    "for img in os.listdir(train_img_path):\n",
    "    img = cv2.imread(train_img_path + img, 1)# 1 means read as RGB\n",
    "    train_images.append(img)\n",
    "            \n",
    "train_images = np.array(train_images)\n",
    "\n",
    "for img in os.listdir(train_msk_path):\n",
    "    img = cv2.imread(train_msk_path + img, 0)# 0 means read as grayscale\n",
    "    train_masks.append(np.array(img))\n",
    "            \n",
    "train_masks = np.array(train_masks)/255\n",
    "y_train = np.expand_dims(train_masks, axis=3).astype(int)\n",
    "\n",
    "for img in os.listdir(test_img_path):\n",
    "    img = cv2.imread(test_img_path + img, 1)\n",
    "    test_images.append(np.array(img))\n",
    "            \n",
    "test_images = np.array(test_images)\n",
    "\n",
    "for img in os.listdir(test_msk_path):\n",
    "    image = Image.open(test_msk_path + img)\n",
    "    test_masks.append(np.array(image))\n",
    "            \n",
    "test_masks = np.array(test_masks)/255\n",
    "y_test = np.expand_dims(test_masks, axis=3).astype(int)\n",
    "\n",
    "print(train_images.shape)#[0,..., 255]\n",
    "print(y_train.shape)#[0, 1]\n",
    "print(test_images.shape)#[0,..., 255]\n",
    "print(y_test.shape)#[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reused parameters in all models\n",
    "n_classes=1\n",
    "activation='sigmoid'\n",
    "\n",
    "seed = 42\n",
    "\n",
    "LR = 0.00001\n",
    "optim = tf.keras.optimizers.Adam(LR)\n",
    "'''\n",
    "binary_focal_loss\n",
    "gamma â€“ Float or integer, focusing parameter for modulating factor (1 - p), default 2.0.\n",
    "alpha weighting factor default 0.25.\n",
    "\n",
    "Dice_loss\n",
    "\n",
    "https://segmentation-models.readthedocs.io/en/latest/api.html#losses\n",
    "'''\n",
    "\n",
    "binary_focal_loss = sm.losses.BinaryFocalLoss(alpha=0.25, gamma=4.0)\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "\n",
    "total_loss = binary_focal_loss + dice_loss\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f8554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "# preprocess input\n",
    "X_train = preprocess_input(train_images)\n",
    "X_test = preprocess_input(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_gen_args = dict(rotation_range=90,\n",
    "                         width_shift_range=0.3,\n",
    "                         height_shift_range=0.3,\n",
    "                         shear_range=0.5,\n",
    "                         zoom_range=0.3,\n",
    "                         horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         fill_mode='reflect')\n",
    "\n",
    "mask_data_gen_args = dict(rotation_range=90,\n",
    "                          width_shift_range=0.3,\n",
    "                          height_shift_range=0.3,\n",
    "                          shear_range=0.5,\n",
    "                          zoom_range=0.3,\n",
    "                          horizontal_flip=True,\n",
    "                          vertical_flip=True,\n",
    "                          fill_mode='reflect',\n",
    "                          preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)) #Binarize the output again. \n",
    "\n",
    "\n",
    "\n",
    "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "image_data_generator.fit(X_train, augment=True, seed=seed)\n",
    "\n",
    "train_img_gen = image_data_generator.flow(X_train, seed=seed)\n",
    "test_img_gen = image_data_generator.flow(X_test, seed=seed)\n",
    "\n",
    "msk_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
    "msk_data_generator.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "train_msk_gen = msk_data_generator.flow(y_train, seed=seed)\n",
    "test_msk_gen = msk_data_generator.flow(y_test, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_image_mask_generator(image_generator, mask_generator):\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img, mask) in train_generator:\n",
    "        yield (img, mask)\n",
    "\n",
    "my_generator = my_image_mask_generator(train_img_gen, train_msk_gen)\n",
    "validation_datagen = my_image_mask_generator(test_img_gen, test_msk_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e082adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more sanity check\n",
    "x = train_img_gen.next()\n",
    "y = train_msk_gen.next()\n",
    "for i in range(0,1):\n",
    "    image = x[i]\n",
    "    mask = y[i]\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image[:,:,0], cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(mask[:,:,0], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model1 = sm.Unet(BACKBONE,\n",
    "                 encoder_weights='imagenet',\n",
    "                 encoder_freeze=True,\n",
    "                 decoder_block_type = 'transpose',# I always have better results with transpose then UpSampling\n",
    "                 classes=n_classes,\n",
    "                 activation=activation)\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model1.compile(optimizer=optim,\n",
    "               loss = total_loss,\n",
    "               metrics=metrics)\n",
    "\n",
    "\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=basepath + 'new_models/' +  \"saved_models/\" + BACKBONE + \"-{epoch:02d}-{val_iou_score:.2f}.hdf5\" #File name includes epoch and validation accuracy.\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_iou_score',\n",
    "                           patience=8,\n",
    "                           mode = 'max',\n",
    "                           verbose=1)\n",
    "\n",
    "\n",
    "#Use Mode = max for accuracy and min for loss. \n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor='val_iou_score',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cdf019",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "steps_per_epoch = 3*(len(X_train))//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b78998",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model1.fit(my_generator,\n",
    "                    validation_data=validation_datagen,\n",
    "                    batch_size=batch_size, \n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=steps_per_epoch,\n",
    "                    epochs= 1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0739394",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['iou_score']\n",
    "val_acc = history.history['val_iou_score']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training iou_score')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation iou_score')\n",
    "plt.title('Training and validation iou_score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0efcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_images = []\n",
    "\n",
    "for img in os.listdir(valid_img_path):\n",
    "    if(os.path.isfile(valid_img_path + img)):\n",
    "        img = cv2.imread(valid_img_path + img, 1)\n",
    "        valid_images.append(np.array(img))\n",
    "            \n",
    "valid_images = np.array(valid_images)\n",
    "X_valid = preprocess_input(valid_images)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "valid_masks = []\n",
    "\n",
    "for img in os.listdir(valid_msk_path):\n",
    "    if(os.path.isfile(valid_msk_path + img)):\n",
    "        image = Image.open(valid_msk_path + img)\n",
    "        valid_masks.append(np.array(image))\n",
    "            \n",
    "valid_masks = np.array(valid_masks)/255\n",
    "y_valid = np.expand_dims(valid_masks, axis=3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f608f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "model_name = 'weights-improvement-21-0.71.hdf5'\n",
    "model = keras.models.load_model(basepath + 'new_models/saved_models/' + model_name, compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ = model1.predict(X_valid)\n",
    "y_pred_thresholded = prediction_ > 0.5\n",
    "intersection = np.logical_and(y_valid, y_pred_thresholded)\n",
    "union = np.logical_or(y_valid, y_pred_thresholded)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(\" IoU socre is: \", iou_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
